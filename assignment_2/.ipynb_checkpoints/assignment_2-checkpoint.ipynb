{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Erik Alexander Sandvik <br />\n",
    "Course: STK-IN4300 <br />\n",
    "Assignment number: 2 <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Import required packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 1.20\n",
      "Test error: 1.92\n"
     ]
    }
   ],
   "source": [
    "# Read data from file\n",
    "\n",
    "df = pd.read_csv(\"qsar_aquatic_toxicity.csv\", sep=\";\")\n",
    "\n",
    "\n",
    "# Label the columns\n",
    "\n",
    "names = ['TPSA', 'SAacc', 'H050', 'MLOGP', 'RDCHI', 'GATS1p', 'nN', 'C040', 'LC50']\n",
    "df.columns = names\n",
    "\n",
    "\n",
    "# Split dataframe by features and response variable\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "\n",
    "# Split the data into a test and training set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "\n",
    "# Ordinary Least Squares\n",
    "\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Calculate the predicted response using the training set and test set as inputs\n",
    "\n",
    "y_predict_train = reg.predict(X_train)\n",
    "y_predict_test = reg.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate the training and test error\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "print('Training error: {:.2f}'.format(MSE(y_train, y_predict_train)))\n",
    "print('Test error: {:.2f}'.format(MSE(y_test, y_predict_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-values:\n",
      "\n",
      "const     6.718007e-19\n",
      "TPSA      4.488061e-17\n",
      "SAacc     5.134547e-10\n",
      "H050      4.744807e-01\n",
      "MLOGP     4.216208e-12\n",
      "RDCHI     5.209703e-03\n",
      "GATS1p    6.349095e-04\n",
      "nN        5.909546e-03\n",
      "C040      7.280372e-01\n",
      "Name: P>|t|, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the significance level of each coefficient in the linear model\n",
    "# scikit-learn doesn't have this implemented\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools import add_constant\n",
    "\n",
    "mod = sm.OLS(y_train, add_constant(X_train))\n",
    "fii = mod.fit()\n",
    "p_values = fii.summary2().tables[1]['P>|t|']\n",
    "\n",
    "print(\"P-values:\\n\")\n",
    "print(p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 1.22\n",
      "Test error: 2.02\n",
      "\n",
      "\n",
      "P-values:\n",
      "\n",
      "const     5.831407e-20\n",
      "TPSA      4.879928e-13\n",
      "SAacc     1.190513e-08\n",
      "H050      1.693085e-01\n",
      "MLOGP     1.701730e-12\n",
      "RDCHI     1.398751e-02\n",
      "GATS1p    4.313739e-04\n",
      "nN        6.238373e-01\n",
      "C040      3.955416e-01\n",
      "Name: P>|t|, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Same thing as above, but with dichotomization of the count variables\n",
    "\n",
    "\n",
    "# Subscript d for dichotomization\n",
    "\n",
    "X_d = X.copy()\n",
    "\n",
    "count_variables = ['H050', 'nN', 'C040']\n",
    "\n",
    "for cnt_var in count_variables:\n",
    "    X_d.loc[X[cnt_var] > 0, cnt_var] = 1\n",
    "    \n",
    "X_train_d, X_test_d, y_train, y_test = train_test_split(X_d, y, test_size=0.33, random_state=1)\n",
    "\n",
    "reg_d = linear_model.LinearRegression()\n",
    "\n",
    "reg_d.fit(X_train_d, y_train)\n",
    "\n",
    "y_predict_train_d = reg_d.predict(X_train_d)\n",
    "y_predict_test_d = reg_d.predict(X_test_d)\n",
    "\n",
    "print('Training error: {:.2f}'.format(MSE(y_train, y_predict_train_d)))\n",
    "print('Test error: {:.2f}'.format(MSE(y_test, y_predict_test_d)))\n",
    "\n",
    "mod = sm.OLS(y_train, add_constant(X_train_d))\n",
    "fii = mod.fit()\n",
    "p_values = fii.summary2().tables[1]['P>|t|']\n",
    "\n",
    "print('\\n')\n",
    "print('P-values:\\n')\n",
    "print(p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With dichotomization the test error increases and the p-values of the coefficients increases by orders of magnitude, with the exception of the variable 'C040' where the p-value of the corresponding coefficient is reduced by a factor of ~2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test error: 1.48, Standard deviation: 0.17\n",
      "Average test error dichotomized: 1.53, Standard deviation: 0.17\n"
     ]
    }
   ],
   "source": [
    "# Repeat 200 times\n",
    "\n",
    "av_test_error    = 0\n",
    "av_test_error_d  = 0\n",
    "\n",
    "av_test_error2   = 0\n",
    "av_test_error2_d = 0\n",
    "\n",
    "n = 200\n",
    "\n",
    "for i in range(n):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=i)\n",
    "    X_train_d, X_test_d, y_train, y_test = train_test_split(X_d, y, test_size=0.33, random_state=i)\n",
    "    \n",
    "    reg.fit(X_train, y_train)\n",
    "    reg_d.fit(X_train_d, y_train)\n",
    "    \n",
    "    y_predict = reg.predict(X_test)\n",
    "    y_predict_d = reg_d.predict(X_test_d)\n",
    "    \n",
    "    av_test_error += MSE(y_test, y_predict)\n",
    "    av_test_error_d += MSE(y_test, y_predict_d)\n",
    "    \n",
    "    av_test_error2 += MSE(y_test, y_predict)**2\n",
    "    av_test_error2_d += MSE(y_test, y_predict_d)**2\n",
    "    \n",
    "av_test_error    /= n\n",
    "av_test_error_d  /= n\n",
    "av_test_error2   /= n\n",
    "av_test_error2_d /= n\n",
    "\n",
    "std = np.sqrt(av_test_error2 - av_test_error**2)\n",
    "std_d = np.sqrt(av_test_error2_d - av_test_error_d**2)\n",
    "\n",
    "\n",
    "print(\"Average test error: {:.2f}, Standard deviation: {:.2f}\".format(av_test_error, std))\n",
    "print(\"Average test error dichotomized: {:.2f}, Standard deviation: {:.2f}\".format(av_test_error_d, std_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average test errors are lower than what was obtained before (1.92 and 2.02), but that was just for one particular way of splitting the data for training and testing, where I suppose I just got very unlucky (see the standard deviation). \n",
    "\n",
    "My best guess for why dichotomization leads to a worse result is that dichotomization makes the linear model biased. But the variance of the prediction is about the same with or without dichotomization. According to the bias-variance decomposition, the expected prediction error is increased with dichotomization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 1.92\n",
      "Coefficients:  [ 0.03 -0.02  0.05  0.52  0.43 -0.62 -0.15 -0.04]\n"
     ]
    }
   ],
   "source": [
    "# The first training/test split again\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_predict_test = reg.predict(X_test)\n",
    "\n",
    "error = MSE(y_test, y_predict_test)\n",
    "\n",
    "coeffs = reg.coef_\n",
    "\n",
    "print(\"Error: {:.2f}\".format(error))\n",
    "print(\"Coefficients: \", np.around(coeffs, decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character Variables (Dummies Generated, First Dummies Dropped): []\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'statsmodels.formula.api' has no attribute 'OLS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-e59a3462464a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Forward selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfinal_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackwardSelection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melimination_criteria\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"aic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/STK-IN4300/assignment_2/stepwiseSelection.py\u001b[0m in \u001b[0;36mbackwardSelection\u001b[0;34m(X, y, model_type, elimination_criteria, varchar_process, sl)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwikipedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mwiki\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mStepwise_regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \"\"\"\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__varcharProcessing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvarchar_process\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvarchar_process\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__backwardSelectionRaw__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0melimination_criteria\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melimination_criteria\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/STK-IN4300/assignment_2/stepwiseSelection.py\u001b[0m in \u001b[0;36m__backwardSelectionRaw__\u001b[0;34m(X, y, model_type, elimination_criteria, sl)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0miterations_log\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\nAIC: \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maic\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\nBIC: \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0miterations_log\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\nAIC: \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maic\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\nBIC: \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/STK-IN4300/assignment_2/stepwiseSelection.py\u001b[0m in \u001b[0;36mregressor\u001b[0;34m(y, X, model_type)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m             \u001b[0mregressor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"logistic\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'statsmodels.formula.api' has no attribute 'OLS'"
     ]
    }
   ],
   "source": [
    "# Automated Stepwise forward and backward selection in python\n",
    "# See https://github.com/talhahascelik/python_stepwiseSelection for details\n",
    "\n",
    "import stepwiseSelection as ss\n",
    "\n",
    "# Forward selection\n",
    "final_vars, _ = ss.backwardSelection(X, y, model_type =\"linear\", elimination_criteria = \"aic\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
